{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbec7ccb",
   "metadata": {},
   "source": [
    "* Source blog: https://pieriantraining.com/confusion-matrix-with-scikit-learn-and-python/\n",
    "\n",
    "##### Confusion Matrix:\n",
    "A confusion matrix is a table used to evaluate the performance of a machine learning algorithm. It shows how many samples were correctly or incorrectly classified by the algorithm in each class.\n",
    "\n",
    "The confusion matrix has two dimensions: actual and predicted. In binary classification, where there are only two classes (positive and negative), it looks like this:\n",
    "\n",
    "|             | Predicted +ve | Predicted -ve |\n",
    "| ----------- | ------------- | --------- |\n",
    "| Actual +ve| True +ve (TP) | False -ve (FN)|\n",
    "| Actual -ve  | False +ve (FP)| True -ve (TN) |\n",
    "\n",
    "Let’s consider a binary classification problem where we have two classes, “Positive” and “Negative”.\n",
    "\n",
    "###### True Positive (TP): \n",
    "This is when the model correctly predicts that an instance belongs to the positive class when it actually does. In other words, TP refers to the number of positive instances that are correctly predicted as positive by the model.\n",
    "\n",
    "###### True Negative (TN): \n",
    "This is when the model correctly predicts that an instance belongs to the negative class when it actually does. In other words, TN refers to the number of negative instances that are correctly predicted as negative by the model.\n",
    "\n",
    "###### False Positive (FP): \n",
    "This is when the model incorrectly predicts that an instance belongs to the positive class when it actually belongs to the negative class. In other words, FP refers to the number of negative instances that are incorrectly predicted as positive by the model.\n",
    "\n",
    "###### False Negative (FN): \n",
    "This is when the model incorrectly predicts that an instance belongs to the negative class when it actually belongs to the positive class. In other words, FN refers to the number of positive instances that are incorrectly predicted as negative by the model.\n",
    "\n",
    "\n",
    "##### Confusion Matrix Use Cases:\n",
    "A confusion matrix is a commonly used tool in machine learning to evaluate the performance of a classification model. Here are some real-world or business use cases where a confusion matrix can be helpful:\n",
    "\n",
    "* Fraud Detection: A bank uses a machine learning model to identify fraudulent transactions. The confusion matrix helps the bank understand how well the model is performing by showing the number of true positives, true negatives, false positives, and false negatives.\n",
    "* Medical Diagnosis: A hospital uses a machine learning model to diagnose patients with a certain disease. The confusion matrix helps doctors understand how accurate the model is by showing the number of true positives, true negatives, false positives, and false negatives.\n",
    "* Customer Churn Prediction: A company uses a machine learning model to predict which customers are likely to churn (stop using their service). The confusion matrix helps the company understand how well the model is performing by showing the number of true positives, true negatives, false positives, and false negatives.\n",
    "* Sentiment Analysis: A social media platform uses a machine learning model to analyze user comments and determine if they are positive or negative. The confusion matrix helps the platform understand how accurate the model is by showing the number of true positives, true negatives, false positives, and false negatives.\n",
    "* Image Classification: An e-commerce website uses a machine learning model to automatically classify product images into different categories like apparel or electronics. The confusion matrix helps them understand how well their image classification algorithm is performing by showing the number of true positives, true negatives, false positives and false negatives for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c952fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59cac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7333578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a394ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regression model on the training data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f85797c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data using the trained model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05b8b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[51  2]\n",
      " [ 6 84]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix of predicted vs actual values\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da852cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f8001af28b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Confusion Matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba90ddb",
   "metadata": {},
   "source": [
    "Based on the Confusion Matrix we can calcluate various accuracy measures. Each of the below measure is relevent for different contexts & applications.\n",
    "\n",
    "##### 1) Accuracy measures\n",
    "is the ratio of correctly classified samples to the total number of samples in the dataset.\n",
    "###### Accuracy = (Number of correctly classified samples) / (Total number of samples)\n",
    "\n",
    "For example, if we have a dataset with 1000 samples and our model correctly classifies 900 out of those 1000 samples, then the accuracy of our model would be:\n",
    "\n",
    "Accuracy = 900/1000 = 0.9 or 90%\n",
    "\n",
    "In other words, our model has an accuracy rate of 90%, meaning that it is able to correctly classify 90% of the samples in the dataset.\n",
    "\n",
    "While accuracy is a commonly used metric for evaluating classification models, it may not always be the best metric to use. For instance, if we have an imbalanced dataset where there are significantly more examples from one class than another, then even a simple model that always predicts the majority class will have high accuracy but may not be useful in practice. Therefore, it’s important to consider other metrics such as precision and recall alongside accuracy when evaluating classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7a9aa1",
   "metadata": {},
   "source": [
    "##### 2) Precision\n",
    "is the ratio of true positive samples to all the predicted positive samples.\n",
    "###### Precision = (True positives) / (True positives + False positives)\n",
    "\n",
    "where True positives are the number of correctly classified positive samples and False positives are the number of negative samples that were incorrectly classified as positive.\n",
    "\n",
    "For example, if our model has predicted 100 samples as positive out of which 80 are actually positive and 20 are negative, then the precision of our model would be:\n",
    "\n",
    "Precision = 80/(80+20) = 0.8 or 80%\n",
    "\n",
    "This means that out of all the samples our model predicted as positive, it was able to correctly classify 80% of them as truly positive.\n",
    "\n",
    "Precision is an important metric when we want to avoid false positives. For instance, in a medical diagnosis scenario where we want to identify patients who have a particular disease, we may want to ensure that we don’t falsely classify healthy patients as having the disease. In such cases, we would aim for a high precision value.\n",
    "\n",
    "However, optimizing for high precision may lead to low recall (the ability to detect all relevant cases), and vice versa. Therefore, it’s important to consider both metrics together when evaluating classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e90ee",
   "metadata": {},
   "source": [
    "##### 3) Recall\n",
    "measures how well a model is able to correctly identify all positive samples from the total number of positive samples in the dataset. It is defined as the ratio of true positive samples to all positive samples.\n",
    "###### Recall = (True positives) / (True positives + False negatives)\n",
    "\n",
    "where True positives are the number of correctly classified positive samples and False negatives are the number of positive samples that were incorrectly classified as negative.\n",
    "\n",
    "For example, if our model has correctly identified 80 out of 100 positive samples in our dataset and missed 20 positive cases, then the recall value would be:\n",
    "\n",
    "Recall = 80/(80+20) = 0.8 or 80%\n",
    "\n",
    "This means that our model was able to correctly identify 80% of all the actual positive cases in our dataset.\n",
    "\n",
    "Recall is an important metric when we want to avoid false negatives. For instance, in a medical diagnosis scenario where we want to identify patients who have a particular disease, we may want to ensure that we don’t miss any patients who actually have the disease. In such cases, we would aim for a high recall value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21456d12",
   "metadata": {},
   "source": [
    "##### 4) F1-Score\n",
    "combines both precision and recall into a single score. It is the harmonic mean of precision and recall, and provides a balance between the two metrics.\n",
    "\n",
    "###### F1-score = 2 * ((Precision * Recall) / (Precision + Recall))\n",
    "\n",
    "where Precision is the ratio of true positive samples to all predicted positive samples, and Recall is the ratio of true positive samples to all actual positive samples.\n",
    "\n",
    "For example, if our model has precision of 0.8 (80%) and recall of 0.85 (85%), then the F1-score would be:\n",
    "\n",
    "F1-score = 2((0.80.85)/(0.8+0.85)) = 0.82 or 82%\n",
    "\n",
    "This means that our model has an overall performance score of 82%, which takes into account both precision and recall.\n",
    "\n",
    "F1-score is useful when we want to have a balance between precision and recall, especially in cases where both false positives and false negatives are equally important to avoid. For instance, in spam email classification where we want to avoid classifying legitimate emails as spam (false positive) as well as missing out on actual spam emails (false negative), we would aim for a high F1-score value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d504e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
