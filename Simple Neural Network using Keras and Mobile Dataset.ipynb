{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d203752",
   "metadata": {},
   "source": [
    "#### Simple Neural Network in Keras\n",
    "* Source blog: https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5\n",
    "* Source data: https://www.kaggle.com/iabhishekofficial/mobile-price-classification (both training & test csv files)\n",
    "\n",
    "##### Step 1:Preprocess and load data: \n",
    "Data is the key for the working of neural network and we need to process it before feeding to the neural network. Also visualize data which will help us to gain insight into the data.\n",
    "\n",
    "##### Step 2: Define model:\n",
    "Next define neural network model. That is specify the number of hidden layers in the neural network and their size, the input and output size.\n",
    "\n",
    "##### Step 3: Loss and optimizer:\n",
    "Next define the loss function according to our task. We also need to specify the optimizer to use with learning rate and other hyperparameters of the optimizer.\n",
    "\n",
    "##### Step 4: Fit model:\n",
    "This is the training step of the neural network. Here we need to define the number of epochs for which we need to train the neural network.\n",
    "\n",
    "##### Step 5: Test model:\n",
    "Now test it on test data to check if it is overfitting. We can save weights of the model and use it later whenever required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87153ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9372\\3208813603.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msidecar_evaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Python module for evaluation loop.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# isort: off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d571c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1004</td>\n",
       "      <td>1654</td>\n",
       "      <td>1067</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1821</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>381</td>\n",
       "      <td>1018</td>\n",
       "      <td>3220</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>1149</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1445</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>386</td>\n",
       "      <td>836</td>\n",
       "      <td>1099</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1137</td>\n",
       "      <td>1224</td>\n",
       "      <td>513</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "5           1859     0          0.5         1   3       0          22    0.7   \n",
       "6           1821     0          1.7         0   4       1          10    0.8   \n",
       "7           1954     0          0.5         1   0       0          24    0.8   \n",
       "8           1445     1          0.5         0   0       0          53    0.7   \n",
       "9            509     1          0.6         1   2       1           9    0.1   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "5        164        1  ...       1004      1654  1067    17     1         10   \n",
       "6        139        8  ...        381      1018  3220    13     8         18   \n",
       "7        187        4  ...        512      1149   700    16     3          5   \n",
       "8        174        7  ...        386       836  1099    17     1         20   \n",
       "9         93        5  ...       1137      1224   513    19    10         12   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "5        1             0     0            1  \n",
       "6        1             0     1            3  \n",
       "7        1             1     1            0  \n",
       "8        1             0     0            0  \n",
       "9        1             0     0            0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#dataset import\n",
    "dataset = pd.read_csv('mobiletrain.csv')\n",
    "dataset.head(10) #Return 10 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d050b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing pandas dataframe to numpy array\n",
    "X = dataset.iloc[:,:20].values\n",
    "y = dataset.iloc[:,20:21].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d86ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68ea474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1408f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d4d67f",
   "metadata": {},
   "source": [
    "##### Building Neural Network\n",
    "Keras is a simple tool for constructing a neural network. It is a high-level framework based on tensorflow, theano or cntk backends.\n",
    "In our dataset, the input is of 20 values and output is of 4 values. So the input and output layer is of 20 and 4 dimensions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c438f1d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6536\\2063773121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Dependencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msidecar_evaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\distribute\\sidecar_evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;34m\"\"\"Python module for evaluation loop.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# isort: off\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=20, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05841b6e",
   "metadata": {},
   "source": [
    "In our neural network, we are using two hidden layers of 16 and 12 dimension.\n",
    "\n",
    "* Sequential specifies to keras that we are creating model sequentially and the output of each layer we add is input to the next layer we specify.\n",
    "* model.add is used to add a layer to our neural network. We need to specify as an argument what type of layer we want. \n",
    "* The Dense is used to specify the fully connected layer. The arguments of Dense are output dimension which is 16 in the first case, input dimension which is 20 for input dimension and the activation function to be used which is relu in this case. \n",
    "* The second layer is similar, we dont need to specify input dimension as we have defined the model to be sequential so keras will automatically consider input dimension to be same as the output of last layer i.e 16. \n",
    "* In the third layer(output layer) the output dimension is 4(number of classes). \n",
    "* The output layer takes different activation functions and for the case of multiclass classification, it is softmax.\n",
    "\n",
    "Specify the loss function and the optimizer. It is done using compile function in keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adc2534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2026c3",
   "metadata": {},
   "source": [
    "Here loss is cross entropy loss as discussed earlier. Categorical_crossentropy specifies that we have multiple classes. The optimizer is Adam. Metrics is used to specify the way we want to judge the performance of our neural network. Here we have specified it to accuracy.\n",
    "\n",
    "We are done with building a neural network and we will train it.\n",
    "\n",
    "Here we need to specify the input data-> X_train, labels-> y_train, number of epochs(iterations), and batch size. It returns the history of model training. History consists of model accuracy and losses after each epoch. We will visualize it later.\n",
    "\n",
    "Usually, the dataset is very big and we cannot fit complete data at once so we use batch size. This divides our data into batches each of size equal to batch_size. Now only this number of samples will be loaded into memory and processed. Once we are done with one batch it is flushed from memory and the next batch will be processed.\n",
    "\n",
    "Now we have started the training of our neural network. Accuracy achieved is 99.33% as can be seen below in the 100th epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "767a43ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 1s 337us/step - loss: 1.4522 - accuracy: 0.2283\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 1.3956 - accuracy: 0.2644\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 0s 27us/step - loss: 1.3549 - accuracy: 0.3122\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 1.3156 - accuracy: 0.3450\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 1.2705 - accuracy: 0.3950\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 1.2172 - accuracy: 0.4350\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 1.1543 - accuracy: 0.4772\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 1.0800 - accuracy: 0.5183\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.9996 - accuracy: 0.5556\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.9177 - accuracy: 0.6050\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.8383 - accuracy: 0.6478\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 0s 24us/step - loss: 0.7642 - accuracy: 0.6972\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.6985 - accuracy: 0.7456\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.6413 - accuracy: 0.7761\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 0s 25us/step - loss: 0.5906 - accuracy: 0.7994\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 0s 26us/step - loss: 0.5453 - accuracy: 0.8272\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.5048 - accuracy: 0.8350\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.4698 - accuracy: 0.8522\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.4380 - accuracy: 0.8717\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.4086 - accuracy: 0.8806\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.3840 - accuracy: 0.8839\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.3609 - accuracy: 0.8989\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.3396 - accuracy: 0.9033\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.3205 - accuracy: 0.9089\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.3036 - accuracy: 0.9133\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.2881 - accuracy: 0.9194\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.2739 - accuracy: 0.9233\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.2587 - accuracy: 0.9311\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.2466 - accuracy: 0.9283\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.2361 - accuracy: 0.9344\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.2255 - accuracy: 0.9356\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.2165 - accuracy: 0.9356\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.2086 - accuracy: 0.9406\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1994 - accuracy: 0.9433\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1918 - accuracy: 0.9489\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1841 - accuracy: 0.9506\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.1777 - accuracy: 0.9517\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1711 - accuracy: 0.9539\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1651 - accuracy: 0.9578\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1607 - accuracy: 0.9567\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1552 - accuracy: 0.9594\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1499 - accuracy: 0.9606\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1478 - accuracy: 0.9533\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1410 - accuracy: 0.9639\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1364 - accuracy: 0.9600\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.1340 - accuracy: 0.9650\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1281 - accuracy: 0.9667\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.1250 - accuracy: 0.9650\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.1207 - accuracy: 0.9700\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1187 - accuracy: 0.9722\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1158 - accuracy: 0.9694\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1122 - accuracy: 0.9722\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.1083 - accuracy: 0.9744\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1059 - accuracy: 0.9744\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1036 - accuracy: 0.9772\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.1000 - accuracy: 0.9778\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0975 - accuracy: 0.9783\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 0s 23us/step - loss: 0.0951 - accuracy: 0.9783\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0934 - accuracy: 0.9783\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0910 - accuracy: 0.9783\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0896 - accuracy: 0.9806\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0874 - accuracy: 0.9822\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0862 - accuracy: 0.9789\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0823 - accuracy: 0.9844\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0803 - accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0785 - accuracy: 0.9828\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0768 - accuracy: 0.9850\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0765 - accuracy: 0.9844\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0735 - accuracy: 0.9861\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0734 - accuracy: 0.9867\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0699 - accuracy: 0.9872\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0688 - accuracy: 0.9894\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0684 - accuracy: 0.9867\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0671 - accuracy: 0.9861\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0661 - accuracy: 0.9872\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0643 - accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0626 - accuracy: 0.9883\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0611 - accuracy: 0.9883\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0610 - accuracy: 0.9894\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0586 - accuracy: 0.9906\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0581 - accuracy: 0.9889\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0570 - accuracy: 0.9906\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0584 - accuracy: 0.9894\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0553 - accuracy: 0.9906\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0538 - accuracy: 0.9911\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0523 - accuracy: 0.9917\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0512 - accuracy: 0.9933\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0507 - accuracy: 0.9917\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 0s 17us/step - loss: 0.0499 - accuracy: 0.9911\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0486 - accuracy: 0.9922\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0478 - accuracy: 0.9944\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0475 - accuracy: 0.9933\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0463 - accuracy: 0.9939\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0459 - accuracy: 0.9922\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0441 - accuracy: 0.9950\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0432 - accuracy: 0.9950\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 0s 18us/step - loss: 0.0429 - accuracy: 0.9950\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0426 - accuracy: 0.9956\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0411 - accuracy: 0.9950\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0427 - accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65a4f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#Converting predictions to label\n",
    "pred = list()\n",
    "for i in range(len(y_pred)):\n",
    "    pred.append(np.argmax(y_pred[i]))\n",
    "#Converting one hot encoded test label to label\n",
    "test = list()\n",
    "for i in range(len(y_test)):\n",
    "    test.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82485c",
   "metadata": {},
   "source": [
    "This step is inverse one hot encoding process. We will get integer labels using this step. We can predict on test data using a simple method of keras, model.predict(). It will take the test data as input and will return the prediction outputs as softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9b66c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 91.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "a = accuracy_score(pred,test)\n",
    "print('Accuracy is:', a*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9de3e",
   "metadata": {},
   "source": [
    "Training Accuracy is 91% - quite good!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ffe9ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 0s 63us/step - loss: 0.0400 - accuracy: 0.9944 - val_loss: 0.2353 - val_accuracy: 0.9200\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0393 - accuracy: 0.9961 - val_loss: 0.2358 - val_accuracy: 0.9200\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0384 - accuracy: 0.9978 - val_loss: 0.2403 - val_accuracy: 0.9050\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0384 - accuracy: 0.9967 - val_loss: 0.2368 - val_accuracy: 0.9100\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0380 - accuracy: 0.9950 - val_loss: 0.2385 - val_accuracy: 0.9200\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0368 - accuracy: 0.9961 - val_loss: 0.2437 - val_accuracy: 0.9050\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0363 - accuracy: 0.9956 - val_loss: 0.2424 - val_accuracy: 0.9100\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0350 - accuracy: 0.9961 - val_loss: 0.2444 - val_accuracy: 0.9150\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0341 - accuracy: 0.9967 - val_loss: 0.2431 - val_accuracy: 0.9100\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0337 - accuracy: 0.9967 - val_loss: 0.2532 - val_accuracy: 0.9150\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0342 - accuracy: 0.9967 - val_loss: 0.2484 - val_accuracy: 0.9100\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0336 - accuracy: 0.9972 - val_loss: 0.2474 - val_accuracy: 0.9150\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0317 - accuracy: 0.9972 - val_loss: 0.2507 - val_accuracy: 0.9100\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0332 - accuracy: 0.9956 - val_loss: 0.2549 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0318 - accuracy: 0.9967 - val_loss: 0.2549 - val_accuracy: 0.9100\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0329 - accuracy: 0.9956 - val_loss: 0.2507 - val_accuracy: 0.9100\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0300 - accuracy: 0.9972 - val_loss: 0.2552 - val_accuracy: 0.9150\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0299 - accuracy: 0.9978 - val_loss: 0.2622 - val_accuracy: 0.9050\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0293 - accuracy: 0.9972 - val_loss: 0.2609 - val_accuracy: 0.9100\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0282 - accuracy: 0.9983 - val_loss: 0.2625 - val_accuracy: 0.9100\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0281 - accuracy: 0.9978 - val_loss: 0.2606 - val_accuracy: 0.9100\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0277 - accuracy: 0.9978 - val_loss: 0.2688 - val_accuracy: 0.9050\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0268 - accuracy: 0.9978 - val_loss: 0.2681 - val_accuracy: 0.9150\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0263 - accuracy: 0.9983 - val_loss: 0.2640 - val_accuracy: 0.9100\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0261 - accuracy: 0.9983 - val_loss: 0.2674 - val_accuracy: 0.9100\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0258 - accuracy: 0.9978 - val_loss: 0.2683 - val_accuracy: 0.9050\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0253 - accuracy: 0.9994 - val_loss: 0.2727 - val_accuracy: 0.9100\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0263 - accuracy: 0.9972 - val_loss: 0.2770 - val_accuracy: 0.9100\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0245 - accuracy: 0.9989 - val_loss: 0.2657 - val_accuracy: 0.9100\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0241 - accuracy: 0.9989 - val_loss: 0.2678 - val_accuracy: 0.9100\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0233 - accuracy: 0.9989 - val_loss: 0.2759 - val_accuracy: 0.9050\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0233 - accuracy: 0.9994 - val_loss: 0.2688 - val_accuracy: 0.9050\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0230 - accuracy: 0.9994 - val_loss: 0.2775 - val_accuracy: 0.9150\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0225 - accuracy: 0.9989 - val_loss: 0.2737 - val_accuracy: 0.9100\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0221 - accuracy: 0.9994 - val_loss: 0.2754 - val_accuracy: 0.9100\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0223 - accuracy: 0.9989 - val_loss: 0.2875 - val_accuracy: 0.9050\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0212 - accuracy: 0.9994 - val_loss: 0.2741 - val_accuracy: 0.9100\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0207 - accuracy: 0.9989 - val_loss: 0.2838 - val_accuracy: 0.9050\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0207 - accuracy: 0.9994 - val_loss: 0.2760 - val_accuracy: 0.9050\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0204 - accuracy: 0.9989 - val_loss: 0.2879 - val_accuracy: 0.9100\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0202 - accuracy: 0.9989 - val_loss: 0.2827 - val_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0197 - accuracy: 0.9989 - val_loss: 0.2900 - val_accuracy: 0.9100\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0191 - accuracy: 0.9994 - val_loss: 0.2893 - val_accuracy: 0.9050\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0200 - accuracy: 0.9989 - val_loss: 0.2902 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0191 - accuracy: 0.9994 - val_loss: 0.2896 - val_accuracy: 0.9100\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0182 - accuracy: 0.9989 - val_loss: 0.2940 - val_accuracy: 0.9100\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0188 - accuracy: 0.9989 - val_loss: 0.2957 - val_accuracy: 0.9100\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 0s 22us/step - loss: 0.0179 - accuracy: 0.9994 - val_loss: 0.2957 - val_accuracy: 0.9100\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0174 - accuracy: 0.9994 - val_loss: 0.2934 - val_accuracy: 0.9100\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0175 - accuracy: 0.9994 - val_loss: 0.2940 - val_accuracy: 0.9100\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0172 - accuracy: 0.9994 - val_loss: 0.3057 - val_accuracy: 0.9100\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0172 - accuracy: 0.9994 - val_loss: 0.2947 - val_accuracy: 0.9100\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0167 - accuracy: 0.9989 - val_loss: 0.3071 - val_accuracy: 0.9100\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0163 - accuracy: 0.9994 - val_loss: 0.2976 - val_accuracy: 0.9100\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 0s 34us/step - loss: 0.0158 - accuracy: 0.9994 - val_loss: 0.3008 - val_accuracy: 0.9100\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0160 - accuracy: 0.9994 - val_loss: 0.3057 - val_accuracy: 0.9000\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0153 - accuracy: 0.9994 - val_loss: 0.3055 - val_accuracy: 0.9100\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0152 - accuracy: 0.9994 - val_loss: 0.3087 - val_accuracy: 0.9100\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0150 - accuracy: 0.9994 - val_loss: 0.3086 - val_accuracy: 0.9100\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0150 - accuracy: 0.9994 - val_loss: 0.3136 - val_accuracy: 0.9050\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0146 - accuracy: 0.9994 - val_loss: 0.3118 - val_accuracy: 0.9100\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0143 - accuracy: 0.9994 - val_loss: 0.3110 - val_accuracy: 0.9100\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0143 - accuracy: 0.9994 - val_loss: 0.3073 - val_accuracy: 0.9100\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0136 - accuracy: 0.9994 - val_loss: 0.3170 - val_accuracy: 0.9100\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0133 - accuracy: 0.9994 - val_loss: 0.3124 - val_accuracy: 0.9100\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0132 - accuracy: 0.9994 - val_loss: 0.3120 - val_accuracy: 0.9100\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0129 - accuracy: 0.9994 - val_loss: 0.3136 - val_accuracy: 0.9100\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0129 - accuracy: 0.9994 - val_loss: 0.3203 - val_accuracy: 0.9100\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0132 - accuracy: 0.9994 - val_loss: 0.3253 - val_accuracy: 0.9100\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0125 - accuracy: 0.9994 - val_loss: 0.3091 - val_accuracy: 0.9100\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0152 - accuracy: 0.9983 - val_loss: 0.3214 - val_accuracy: 0.9050\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0124 - accuracy: 0.9994 - val_loss: 0.3176 - val_accuracy: 0.9100\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0119 - accuracy: 0.9994 - val_loss: 0.3144 - val_accuracy: 0.9050\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0122 - accuracy: 0.9994 - val_loss: 0.3204 - val_accuracy: 0.9050\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0113 - accuracy: 0.9994 - val_loss: 0.3231 - val_accuracy: 0.9100\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0114 - accuracy: 0.9994 - val_loss: 0.3277 - val_accuracy: 0.9050\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0111 - accuracy: 0.9994 - val_loss: 0.3261 - val_accuracy: 0.9050\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0118 - accuracy: 0.9994 - val_loss: 0.3354 - val_accuracy: 0.9000\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0112 - accuracy: 0.9994 - val_loss: 0.3275 - val_accuracy: 0.9050\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0106 - accuracy: 0.9994 - val_loss: 0.3333 - val_accuracy: 0.9050\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.3346 - val_accuracy: 0.9050\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0103 - accuracy: 0.9994 - val_loss: 0.3325 - val_accuracy: 0.9050\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9050\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0103 - accuracy: 0.9994 - val_loss: 0.3323 - val_accuracy: 0.9050\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0100 - accuracy: 0.9994 - val_loss: 0.3399 - val_accuracy: 0.9050\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0096 - accuracy: 0.9994 - val_loss: 0.3404 - val_accuracy: 0.9050\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0095 - accuracy: 0.9994 - val_loss: 0.3420 - val_accuracy: 0.9050\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9050\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.3465 - val_accuracy: 0.9050\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.3438 - val_accuracy: 0.9050\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0091 - accuracy: 0.9994 - val_loss: 0.3407 - val_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0099 - accuracy: 0.9994 - val_loss: 0.3526 - val_accuracy: 0.9050\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0090 - accuracy: 0.9994 - val_loss: 0.3462 - val_accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0087 - accuracy: 0.9994 - val_loss: 0.3496 - val_accuracy: 0.9050\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 0s 19us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9050\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.8950\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9050\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 0s 20us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9050\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 0s 21us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9050\n"
     ]
    }
   ],
   "source": [
    "# USing test data to validate\n",
    "history = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb7e7cb",
   "metadata": {},
   "source": [
    "Now we will visualize training and validation losses and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb298de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95e7941b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e649ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
